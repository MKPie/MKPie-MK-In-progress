from main import SheetRow, MainWindow
from decorators import retry_on_failure
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
import traceback
from webscraper_wrapper import create_webscraper_wrapper
from PyQt5.QtWidgets import QApplication, QMessageBox
from PyQt5.QtCore import QTimer
import pandas as pd
import os
import time
import re

def patched_scrape_katom(self, model_number, prefix, retries=2):
    model_number = ''.join(e for e in model_number if e.isalnum()).upper()
    if model_number.endswith("HC"):
        model_number = model_number[:-2]
    url = f"https://www.katom.com/{prefix}-{model_number}.html"
    print(f"Scraping: {url}")
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
    title, description = "Title not found", "Description not found"
    specs_data = {}
    specs_html = ""
    video_links = ""
    main_image = ""
    additional_images = []
    for attempt in range(retries + 1):
        driver = None
        try:
            options = Options()
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument(f'user-agent={user_agent}')
            driver = webdriver.Chrome(options=options)
            driver.set_page_load_timeout(30)
            driver.get(url)
            if "404" in driver.title or "not found" in driver.title.lower():
                print(f"Product not found at {url}")
                return title, description, specs_data, specs_html, video_links, main_image, additional_images
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "h1.product-name.mb-0"))
            )
            title_element = driver.find_element(By.CSS_SELECTOR, "h1.product-name.mb-0")
            title = title_element.text.strip()
            if title:
                try:
                    tab_content = driver.find_element(By.CLASS_NAME, "tab-content")
                    paragraphs = tab_content.find_elements(By.TAG_NAME, "p")
                    filtered = [
                        f"<p>{p.text.strip()}</p>" for p in paragraphs
                        if p.text.strip() and not p.text.lower().startswith("*free") and "video" not in p.text.lower()
                    ]
                    description = "".join(filtered) if filtered else "Description not found"
                except NoSuchElementException:
                    print(f"Tab content not found on {url}")
                specs_data, specs_html = self.extract_table_data(driver)
                try:
                    sources = driver.find_elements(By.CSS_SELECTOR, "source[src*='.mp4'], source[type*='video']")
                    for source in sources:
                        src = source.get_attribute("src")
                        if src and src not in video_links:
                            video_links += f"{src}\n"
                    if not video_links:
                        videos = driver.find_elements(By.TAG_NAME, "video")
                        for video in videos:
                            inner_sources = video.find_elements(By.TAG_NAME, "source")
                            for source in inner_sources:
                                src = source.get_attribute("src")
                                if src and src not in video_links:
                                    video_links += f"{src}\n"
                    if not video_links:
                        page_source = driver.page_source
                        mp4_pattern = r'https?://[^"\']+\.mp4'
                        matches = re.findall(mp4_pattern, page_source)
                        for match in matches:
                            if match not in video_links:
                                video_links += f"{match}\n"
                except Exception as e:
                    print(f"Error extracting video links: {e}")
                try:
                    main_img_elem = driver.find_element(By.CSS_SELECTOR, "img.main-image, img.product-image")
                    main_image = main_img_elem.get_attribute("src")
                    img_elems = driver.find_elements(By.CSS_SELECTOR, "img.additional-image, .gallery-image")
                    additional_images = [img.get_attribute("src") for img in img_elems][:5]
                except Exception as e:
                    print(f"Image scraping error: {e}")
                break
        except Exception as e:
            print(f"Error in scrape attempt {attempt+1}: {e}")
            traceback.print_exc()
            if attempt < retries:
                retry_wait = (attempt + 1) * 2
                print(f"Retry {attempt+1}/{retries} in {retry_wait} seconds...")
                time.sleep(retry_wait)
        finally:
            if driver:
                try:
                    driver.quit()
                except:
                    pass
    return title, description, specs_data, specs_html, video_links, main_image, additional_images

@retry_on_failure(max_attempts=4, delay=3)
def wrapped_scrape_katom(self, model_number, prefix):
    return patched_scrape_katom(self, model_number, prefix)

def patched_process_file(self, filepath, prefix):
    try:
        print(f"Processing file: {filepath} with prefix: {prefix}")
        file_extension = os.path.splitext(filepath)[1].lower()
        if file_extension == ".xlsx":
            df = pd.read_excel(filepath, engine="openpyxl")
        elif file_extension == ".csv":
            df = pd.read_csv(filepath)
        else:
            raise ValueError(f"Unsupported file type: {file_extension}")
        output_columns = ["Mfr Model"]
        plugin_manager = getattr(self.parent, "plugin_manager", None)
        if plugin_manager and "Field Selector" in plugin_manager.plugins:
            selected_fields = plugin_manager.plugins["Field Selector"]["config"]["selected_fields"]
            output_columns.extend([field for field in selected_fields if selected_fields[field]])
            output_columns.extend([cf["name"] for cf in plugin_manager.plugins["Field Selector"]["config"]["custom_fields"] if cf["enabled"]])
        unique_columns = []
        seen = set()
        for col in output_columns:
            if col not in seen:
                unique_columns.append(col)
                seen.add(col)
            else:
                print(f"Skipping duplicate column: {col}")
        self.output_df = pd.DataFrame(columns=unique_columns)
        for index, row in df.iterrows():
            try:
                model_number = str(row.get("Model Number", ""))
                if not model_number or pd.isna(model_number):
                    print(f"Skipping row {index + 1}: Missing model number")
                    continue
                new_row = self.scrape_katom(model_number, prefix)
                if new_row:
                    new_row["Mfr Model"] = model_number
                    new_row_df = pd.DataFrame([new_row], columns=unique_columns)
                    self.output_df = pd.concat([self.output_df, new_row_df], ignore_index=True)
                else:
                    print(f"No data scraped for model: {model_number}")
            except Exception as e:
                print(f"Error processing row {index + 1}: {e}")
                traceback.print_exc()
        print(f"DataFrame shape: {self.output_df.shape}")
        print(f"DataFrame columns: {list(self.output_df.columns)}")
        if self.output_df.empty:
            print("WARNING: DataFrame is empty - no rows to save")
            return
        output_dir = os.path.expanduser("~/GoogleDriveMount/Web/Completed/Final/")
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"final_{prefix}{os.path.splitext(os.path.basename(filepath))[0]}.xlsx"
        output_path = os.path.join(output_dir, output_filename)
        print(f"Saving output file to: {output_path}")
        self.output_df.to_excel(output_path, index=False, engine="openpyxl")
    except Exception as e:
        print(f"Error processing file: {e}")
        traceback.print_exc()
        QMessageBox.warning(self.parent, "Error", f"Error processing file: {str(e)}")



def apply_patches():
    SheetRow.scrape_katom = wrapped_scrape_katom
    SheetRow.process_file = patched_process_file
    MainWindow.add_row = patched_add_row

    SheetRow.scrape_katom = wrapped_scrape_katom
    SheetRow.process_file = patched_process_file
    MainWindow.add_row = patched_add_row
